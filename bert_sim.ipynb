{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sem.kolesnikov/proj/TextsGraphCompare/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      ".gitattributes: 100%|██████████| 737/737 [00:00<00:00, 99.3kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 127kB/s]\n",
      "README.md: 100%|██████████| 8.66k/8.66k [00:00<00:00, 7.54MB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 516kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 106kB/s]\n",
      "data_config.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 6.41MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [01:12<00:00, 6.02MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 21.9kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 78.8kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.20MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 146kB/s]\n",
      "train_script.py: 100%|██████████| 13.9k/13.9k [00:00<00:00, 5.17MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 9.43MB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 86.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.6146\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.5309\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9582\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('cc.ru.300.vec.gz', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('data/docs.json') as f:\n",
    "    raw_docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Document\n",
    "\n",
    "\n",
    "raw_docs = [Document(key, value.split()) for key, value in raw_docs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1236/1236 [15:59<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "doc_to_embed = {}\n",
    "for doc_name, text in tqdm.tqdm(raw_docs.items()):\n",
    "    doc_to_embed[doc_name] = model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "from importlib import reload\n",
    "common = reload(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1236it [00:16, 74.33it/s] \n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import scoring\n",
    "from functools import partial\n",
    "from common import cosine_sim, get_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1236it [00:12, 96.89it/s] \n"
     ]
    }
   ],
   "source": [
    "graph = get_graph(raw_docs, 0.8, partial(cosine_sim, doc_to_vec=doc_to_embed))\n",
    "\n",
    "doc_name_to_doc = {doc.name: doc for doc in raw_docs}\n",
    "\n",
    "components = list(nx.connected_components(graph))\n",
    "len(components)\n",
    "components_docs = [\n",
    "    Document(k, sum((doc_name_to_doc[doc_name].tokens for doc_name in docs_names), []))\n",
    "    for k, docs_names in enumerate(components)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:00, 104.14it/s]\n"
     ]
    }
   ],
   "source": [
    "component_to_topics = scoring.get_topics_ctfidf(components_docs, reduce_frequent_words=True, bm25_weighting=True, top_k=10, min_df=0.3, max_df=0.8)\n",
    "components_topics = [v for k, v in component_to_topics.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20811919490389272"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common.compute_top_words_sim(components_topics, model, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
