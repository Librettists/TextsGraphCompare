{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "\n",
    "from data_reader import JsonDocReader, PostPdfDocReader, Document\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "from joblib import Parallel, delayed\n",
    "import octis\n",
    "import common\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ГОСТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sem.kolesnikov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 10/10 [00:00<00:00, 2534.17it/s]\n"
     ]
    }
   ],
   "source": [
    "data_reader = JsonDocReader(Path('data/docs.json')).read_documents()\n",
    "docs = list(data_reader)\n",
    "filtered_docs = common.filter_common_words(docs, min_freq=0, max_freq=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1236/1236 [00:02<00:00, 430.21it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('data/preprocessed_docs.json') as f:\n",
    "    docs = json.load(f)\n",
    "    docs = [Document(k, v.split()) for k, v in docs.items()]\n",
    "filtered_docs = common.filter_common_words(docs, min_freq=0.1, max_freq=0.65)\n",
    "doc_name_to_doc = {doc.name: doc for doc in docs}\n",
    "filtered_docs.remove(Document('gost_r_54481-2011.txt', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1235it [01:22, 15.00it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = common.get_graph(filtered_docs, 0.85, partial(common.jaccard_sim, _words_cache={}))\n",
    "doc_name_to_doc = {doc.name: doc for doc in docs}\n",
    "\n",
    "components = list(nx.connected_components(graph))\n",
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoring\n",
    "from importlib import reload\n",
    "scoring = reload(scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 504.81it/s]\n"
     ]
    }
   ],
   "source": [
    "components_docs = [\n",
    "    Document(k, sum((doc_name_to_doc[doc_name].tokens for doc_name in docs_names), []))\n",
    "    for k, docs_names in enumerate(components)\n",
    "]\n",
    "component_to_topics = scoring.get_topics_ctfidf(components_docs, reduce_frequent_words=True, bm25_weighting=False, top_k=10, min_df=0.1, max_df=0.85)\n",
    "components_topics = [v for k, v in component_to_topics.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['заявление',\n",
       " 'регистрация',\n",
       " 'выдача',\n",
       " 'орган',\n",
       " 'агентство',\n",
       " 'заявитель',\n",
       " 'единица',\n",
       " 'реестр',\n",
       " 'обязанность',\n",
       " 'присвоение']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_to_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.coherence_metrics import WECoherencePairwise\n",
    "\n",
    "pairwise = WECoherencePairwise('cc.ru.300.vec.gz', binary=False, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034275747549654255"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise.score({'topics': components_topics})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alexandra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2454/2454 [01:16<00:00, 32.01it/s]\n",
      "100%|██████████| 2454/2454 [00:09<00:00, 270.93it/s]\n"
     ]
    }
   ],
   "source": [
    "articles = list(PostPdfDocReader().read_saved_as_document(\"upd\"))\n",
    "filtered_articles = common.filter_common_words(articles, min_freq=0, max_freq=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph = common.get_graph(filtered_articles, 0.85, partial(common.jaccard_sim, _words_cache={}))\n",
    "\n",
    "import pickle\n",
    "with open('jac_graph.pickle', 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "doc_name_to_doc = {doc.name: doc for doc in articles}\n",
    "\n",
    "components = list(nx.connected_components(graph))\n",
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Внутренняя торговля. Туристско-экскурсионное обслуживание-15487913_14760873.csv',\n",
       "  'Внутренняя торговля. Туристско-экскурсионное обслуживание-15487913_41307961.csv'},\n",
       " {'Информатика-36462175_17151772.csv', 'Информатика-36462175_86833932.csv'},\n",
       " {'Кибернетика-48968947_50106637.csv', 'Кибернетика-48968947_63817574.csv'},\n",
       " {'Космические исследования-46357156_20482003.csv',\n",
       "  'Космические исследования-46357156_44596993.csv'},\n",
       " {'Культура. Культурология-11659345_42976510.csv',\n",
       "  'Культура. Культурология-11659345_66404855.csv'},\n",
       " {'Культура. Культурология-38569997_47758309.csv',\n",
       "  'Культура. Культурология-38569997_81188332.csv'},\n",
       " {'Культура. Культурология-41871153_84879739.csv',\n",
       "  'Культура. Культурология-41871153_87245919.csv'},\n",
       " {'Культура. Культурология-44557483_82171609.csv',\n",
       "  'Культура. Культурология-44557483_93330972.csv'},\n",
       " {'Лесная и деревообрабатывающая промышленность-42446382_51614510.csv',\n",
       "  'Лесная и деревообрабатывающая промышленность-42446382_56625649.csv'},\n",
       " {'Машиностроение-34963339_57147500.csv',\n",
       "  'Машиностроение-34963339_62423684.csv'},\n",
       " {'Машиностроение-36588897_41421944.csv',\n",
       "  'Машиностроение-36588897_41555154.csv'},\n",
       " {'Физика-11032189_86277749.csv', 'Физика-11032189_88826577.csv'},\n",
       " {'Физическая культура и спорт-16757256_26407754.csv',\n",
       "  'Физическая культура и спорт-16757256_79346749.csv'},\n",
       " {'Электротехника-43030087_21012093.csv',\n",
       "  'Электротехника-43030087_97947976.csv'},\n",
       " {'Ядерная техника-32834328_44441811.csv',\n",
       "  'Ядерная техника-32834328_80419289.csv'},\n",
       " {'Ядерная техника-42647614_17089974.csv',\n",
       "  'Ядерная техника-42647614_28659951.csv'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoring\n",
    "from importlib import reload\n",
    "scoring = reload(scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 73.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['специалист',\n",
       " 'профессиональный',\n",
       " 'подготовка',\n",
       " 'стандарт',\n",
       " 'обслуживание',\n",
       " 'образовательный',\n",
       " 'учебный',\n",
       " 'предприятие',\n",
       " 'требование',\n",
       " 'качество']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_docs = [\n",
    "    Document(k, sum((doc_name_to_doc[doc_name].tokens for doc_name in docs_names), []))\n",
    "    for k, docs_names in enumerate(components)\n",
    "]\n",
    "component_to_topics = scoring.get_topics_ctfidf(components_docs, reduce_frequent_words=True, bm25_weighting=False, top_k=10, min_df=0.1, max_df=0.85)\n",
    "components_topics = [v for k, v in component_to_topics.items()]\n",
    "component_to_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00060675549838278"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from octis.evaluation_metrics.coherence_metrics import WECoherencePairwise\n",
    "\n",
    "pairwise = WECoherencePairwise('cc.ru.300.vec.gz', binary=False, topk=10)\n",
    "pairwise.score({'topics': components_topics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "#mode_graph = graph.copy()\n",
    "with open('jac_graph.pickle', 'rb') as f:\n",
    "    mode_graph = pickle.load(f)\n",
    "\n",
    "node_weights = collections.defaultdict(0)\n",
    "wtot = 0\n",
    "for (u,v) in mode_graph.edges():\n",
    "    weight = mode_graph[u][v]['weight']\n",
    "    node_weights[u] += weight\n",
    "    node_weights[v] += weight\n",
    "    wtot += weight\n",
    "    if u != v:\n",
    "        wtot += weight\n",
    "\n",
    "cluster_sizes = collections.defaultdict(1)\n",
    "connected_components = []\n",
    "D = []\n",
    "u = mode_graph.number_of_nodes()\n",
    "for n in mode_graph.nodes():\n",
    "    neighbor_chain = [list(mode_graph.nodes())[0]]\n",
    "    while neighbor_chain != []:\n",
    "        a = neighbor_chain.pop()\n",
    "        dmin = float(\"inf\")\n",
    "        nearest = -1\n",
    "        for v in neighbor_chain.neighbors(a):\n",
    "            if v != a:\n",
    "                d = node_weights[v] * node_weights[a] / float(mode_graph[a][v]['weight']) / float(wtot)\n",
    "                if d < dmin:\n",
    "                    nearest = v\n",
    "                    dmin = d\n",
    "                elif d == dmin:\n",
    "                    nearest = min(nearest,v)\n",
    "        d = dmin\n",
    "        if neighbor_chain != []:\n",
    "            c = neighbor_chain.pop()\n",
    "            if nearest == c:\n",
    "                D.append([a,nearest,d,cluster_sizes[a] + cluster_sizes[nearest]])\n",
    "                    # update graph\n",
    "                mode_graph.add_node(u)\n",
    "                neighbors_a = list(mode_graph.neighbors(a))\n",
    "                neighbors_b = list(mode_graph.neighbors(nearest))\n",
    "                for v in neighbors_a:\n",
    "                    mode_graph.add_edge(u,v,weight = mode_graph[a][v]['weight'])\n",
    "                for v in neighbors_b:\n",
    "                    if mode_graph.has_edge(u,v):\n",
    "                        mode_graph[u][v]['weight'] += mode_graph[nearest][v]['weight']\n",
    "                    else:\n",
    "                        mode_graph.add_edge(u,v,weight = mode_graph[nearest][v]['weight'])\n",
    "                mode_graph.remove_node(a)\n",
    "                mode_graph.remove_node(nearest)\n",
    "                node_weights[u] = node_weights.pop(a) + node_weights.pop(nearest)\n",
    "                cluster_sizes[u] = cluster_sizes.pop(a) + cluster_sizes.pop(nearest)\n",
    "                u += 1\n",
    "            else:\n",
    "                neighbor_chain.append(c)\n",
    "                neighbor_chain.append(a)\n",
    "                neighbor_chain.append(nearest)\n",
    "        elif nearest >= 0:\n",
    "            neighbor_chain.append(a)\n",
    "            neighbor_chain.append(nearest)   \n",
    "        else:\n",
    "            connected_components.append((a,cluster_sizes[a]))\n",
    "            F.remove_node(a)\n",
    "            w.pop(a)\n",
    "            s.pop(a)\n",
    "            n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
